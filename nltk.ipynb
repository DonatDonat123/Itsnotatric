{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hot Words\n",
    "### named entitiy recognition \n",
    "### Tagging\n",
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nlp_nltk import NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = StanfordNERTagger('./stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                           './stanford-ner/stanford-ner.jar',\n",
    "                           encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(3), array(5)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Testy:\n",
    "    def __init__(self):\n",
    "        self.a = np.array(3)\n",
    "        self.b = np.array(5)\n",
    "        self.c = [self.a, self.b]\n",
    "        \n",
    "t.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input message = Berlin\n",
      "tagged_text: [['Berlin' 'LOCATION']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You want to know more about Berlin, is this correct ?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.respond(\"Berlin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIRMATIONS_SET = {\"yes\", \"y\", \"yep\", \"ok\", \"correct\"}\n",
    "any(s in sentence for s in CONFIRMATIONS_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cities(text):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    tagged_text = np.array(tagger.tag(tokenized_text))\n",
    "    print(tagged_text)\n",
    "    return tagged_text[tagged_text[:,1] == 'LOCATION'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.round(27.62).astype(int)\n",
    "\n",
    "int(27.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Testy:\n",
    "    def __init__(self):\n",
    "        self.a = 2\n",
    "        self.c = 3\n",
    "    def reset(self, obj):\n",
    "        print(obj)\n",
    "        obj = None\n",
    "        self.a = obj\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagged_text: [['Hallo' 'O']\n",
      " [',' 'O']\n",
      " ['give' 'O']\n",
      " ['me' 'O']\n",
      " ['Berlin' 'LOCATION']\n",
      " [',' 'O']\n",
      " ['Valencia' 'ORGANIZATION']\n",
      " ['and' 'O']\n",
      " ['Stuttgart' 'LOCATION']]\n"
     ]
    }
   ],
   "source": [
    "STANFORD_JAR_FILE = './stanford-ner/stanford-ner.jar'\n",
    "STANFORD_ENG_FILE = './stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "tagger = StanfordNERTagger(STANFORD_ENG_FILE, STANFORD_JAR_FILE, encoding='utf-8')\n",
    "\n",
    "text = \"Hallo, give me Berlin, Valencia and Stuttgart\"\n",
    "tokenized_text = word_tokenize(text)\n",
    "tagged_text = np.array(tagger.tag(tokenized_text))\n",
    "print (\"tagged_text: {}\".format(tagged_text))\n",
    "cities = list(tagged_text[tagged_text[:, 1] == 'LOCATION'][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin\n"
     ]
    }
   ],
   "source": [
    "mylist = [\"Berlin\", \"Hamburg\"]\n",
    "for t in tokenized_text:\n",
    "    if t in mylist:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Berlin', 'Bremen', 'Hamburg'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = [\"Berlin\", \"Hamburg\", \"Berlin\"]\n",
    "mylist2 = [\"Bremen\"]\n",
    "leset = set(mylist)\n",
    "leset.update(set(mylist2))\n",
    "leset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
